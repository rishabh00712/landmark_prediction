{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10315070,"sourceType":"datasetVersion","datasetId":6385917}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Essential Libraries\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score\nfrom tqdm import tqdm\nfrom PIL import Image\n\n# Load Dataset Metadata\ndf_train = pd.read_csv('/kaggle/input/google-landmark-v2/train_landmark.csv')\ndf_test = pd.read_csv('/kaggle/input/google-landmark-v2/test_landmark.csv')\n\n# Inspect Data\nprint(\"The Training Data\")\nprint(\"=\" * 100)\nprint(df_train.head(5))\nprint(\"=\" * 100)\n\nprint(\"The Testing Data\")\nprint(\"=\" * 100)\nprint(df_test.head(5))\nprint(\"=\" * 100)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-28T00:34:07.584580Z","iopub.execute_input":"2024-12-28T00:34:07.584878Z","iopub.status.idle":"2024-12-28T00:34:25.574745Z","shell.execute_reply.started":"2024-12-28T00:34:07.584834Z","shell.execute_reply":"2024-12-28T00:34:25.573752Z"}},"outputs":[{"name":"stdout","text":"The Training Data\n====================================================================================================\n                 id                                                url  \\\n0  6e158a47eb2ca3f6  https://upload.wikimedia.org/wikipedia/commons...   \n1  202cd79556f30760  http://upload.wikimedia.org/wikipedia/commons/...   \n2  3ad87684c99c06e1  http://upload.wikimedia.org/wikipedia/commons/...   \n3  e7f70e9c61e66af3  https://upload.wikimedia.org/wikipedia/commons...   \n4  4072182eddd0100e  https://upload.wikimedia.org/wikipedia/commons...   \n\n   landmark_id  \n0       142820  \n1       104169  \n2        37914  \n3       102140  \n4         2474  \n====================================================================================================\nThe Testing Data\n====================================================================================================\n                 id\n0  00016575233bc956\n1  0001aadbcd8cb923\n2  0002c06b2440a5f9\n3  0002eb1ee5a5a6b2\n4  000594dad986513e\n====================================================================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T00:34:25.576105Z","iopub.execute_input":"2024-12-28T00:34:25.576376Z","iopub.status.idle":"2024-12-28T00:34:25.582037Z","shell.execute_reply.started":"2024-12-28T00:34:25.576353Z","shell.execute_reply":"2024-12-28T00:34:25.581362Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"(4132914, 3)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import requests\nfrom tqdm import tqdm\nimport os\nimport shutil\n\n# Create Directory for Images\n# shutil.rmtree('/kaggle/working/train/', ignore_errors=True)\nos.makedirs('/kaggle/working/train/', exist_ok=True)\n\ndef download_images(dataframe, save_dir, max_images=100000):\n    os.makedirs(save_dir, exist_ok=True)\n    downloaded = 0\n\n    for idx, row in tqdm(dataframe.iterrows(), total=min(len(dataframe), max_images), desc='Downloading Images'):\n        if downloaded >= max_images:\n            print(\"Reached maximum download limit.\")\n            break\n\n        img_id = row['id']\n        img_url = row['url']\n        img_path = os.path.join(save_dir, f\"{img_id}.jpg\")\n\n        if os.path.exists(img_path):\n            continue  # Skip already downloaded images\n\n        try:\n            response = requests.get(img_url, timeout=5)\n            if response.status_code == 200:\n                with open(img_path, 'wb') as f:\n                    f.write(response.content)\n                downloaded += 1\n        except requests.exceptions.RequestException as e:\n            print(f\"Failed to download {img_url}: {e}\")\n        \n# Download up to 100,000 images\ndownload_images(df_train, '/kaggle/working/train/', max_images=100000)\nprint(\"Number of images downloaded:\", len(os.listdir('/kaggle/working/train/')))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T00:34:25.584031Z","iopub.execute_input":"2024-12-28T00:34:25.584299Z","execution_failed":"2024-12-28T00:59:18.142Z"}},"outputs":[{"name":"stderr","text":"Downloading Images:  15%|█▌        | 15455/100000 [24:53<2:11:52, 10.68it/s]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Preprocess Dataset\ntrain_df, val_df = train_test_split(df_train, test_size=0.2, random_state=42)\n\n# Custom Dataset Class\nclass LandmarkDataset(Dataset):\n    def __init__(self, dataframe, directory, transform=None, is_test=False):\n        self.dataframe = dataframe\n        self.directory = directory\n        self.transform = transform\n        self.is_test = is_test\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_id = self.dataframe.iloc[idx]['id']\n        img_path = f'{self.directory}/{img_id}.jpg'\n        try:\n            image = Image.open(img_path).convert('RGB')\n        except FileNotFoundError:\n            print(f\"Warning: {img_path} not found.\")\n            return None, None  # Return placeholders if image is missing\n\n        if self.transform:\n            image = self.transform(image)\n        \n        if self.is_test:\n            return image, img_id\n        \n        label = self.dataframe.iloc[idx]['landmark_id']\n        return image, label\n\n# Image Transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n])\n\n# Dataset Instances\ntrain_dataset = LandmarkDataset(train_df, '/kaggle/working/train', transform=transform)\nval_dataset = LandmarkDataset(val_df, '/kaggle/working/train', transform=transform)\ntest_dataset = LandmarkDataset(df_test, '/kaggle/working/train', transform=transform, is_test=True)\n\n# DataLoader Instances\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-28T00:59:18.143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Using Pre-Trained Model for transfer Learning on the Dataset\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"The device in use: {device}\")\n\n# Model Initialization\nmodel = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, len(train_df['landmark_id'].unique()))\nmodel = model.to(device)\n\n# Loss and Optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-28T00:59:18.143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-28T00:59:18.143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training the Model\ndef train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, epochs=30):\n    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n    for epoch in range(epochs):\n        model.train()\n        train_loss, train_correct = 0, 0\n        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n            train_correct += (outputs.argmax(1) == labels).sum().item()\n        \n        val_loss, val_correct = 0, 0\n        model.eval()\n        with torch.no_grad():\n            for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} - Validation\"):\n                images, labels = images.to(device), labels.to(device)\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                val_loss += loss.item()\n                val_correct += (outputs.argmax(1) == labels).sum().item()\n        \n        scheduler.step(val_loss)\n        \n        history['train_loss'].append(train_loss / len(train_loader))\n        history['val_loss'].append(val_loss / len(val_loader))\n        history['train_acc'].append(train_correct / len(train_loader.dataset))\n        history['val_acc'].append(val_correct / len(val_loader.dataset))\n        \n        print(f'Epoch [{epoch+1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}')\n    \n    # Plot Training History\n    plt.figure(figsize=(12, 6))\n    plt.subplot(1, 2, 1)\n    plt.plot(history['train_loss'], label='Train Loss')\n    plt.plot(history['val_loss'], label='Validation Loss')\n    plt.title('Loss per Epoch')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    \n    plt.subplot(1, 2, 2)\n    plt.plot(history['train_acc'], label='Train Accuracy')\n    plt.plot(history['val_acc'], label='Validation Accuracy')\n    plt.title('Accuracy per Epoch')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n    \n    # return history\n\n# history = \ntrain_model(model, criterion, optimizer, scheduler, train_loader, val_loader)\n# torch.save(model.state_dict())","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-28T00:59:18.143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluateing the Model Performance\nmodel.eval()\nall_preds, all_labels = [], []\nwith torch.no_grad():\n    for images, labels in tqdm(val_loader, desc='Evaluation Loop'):\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        preds = outputs.argmax(1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\nf1 = f1_score(all_labels, all_preds, average='weighted')\nprint(f'Validation F1-Score: {f1}')","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-28T00:59:18.143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test Predictions\ncorrect, wrong = 0, 0\nfor images, img_ids in tqdm(test_loader, desc='Test Predictions'):\n    images = images.to(device)\n    outputs = model(images)\n    preds = outputs.argmax(1)\n    for i, img_id in enumerate(img_ids):\n        predicted_class = preds[i].item()\n        correct += 1  # Placeholder for actual comparison logic\n\n# Pie Chart\nlabels = ['Correctly Classified', 'Wrongly Classified']\nsizes = [correct, len(test_loader.dataset) - correct]\ncolors = ['#66b3ff', '#ff6666']\nplt.figure(figsize=(8, 8))\nplt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=140)\nplt.title('Test Dataset Classification Results')\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2024-12-28T00:59:18.143Z"}},"outputs":[],"execution_count":null}]}